from flask import Flask, request, jsonify, render_template, redirect, url_for, session
import sqlite3
import ollama
import logging
import os
import fitz  # PyMuPDF for PDF reading
import docx
import re
import json

# Initialize Flask app
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
logging.basicConfig(level=logging.INFO)

def connect_db():
    return sqlite3.connect("job_screening.db")

# Create tables if not exist
def init_db():
    with connect_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''CREATE TABLE IF NOT EXISTS job_descriptions (
                          id INTEGER PRIMARY KEY, content TEXT)''')
        cursor.execute('''CREATE TABLE IF NOT EXISTS candidates (
                          id INTEGER PRIMARY KEY, resume TEXT)''')
        cursor.execute('''CREATE TABLE IF NOT EXISTS job_listings (
                          id INTEGER PRIMARY KEY, title TEXT, description TEXT)''')
        conn.commit()

init_db()

# Homepage route
def get_job_listings_from_db():
    with connect_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT id, title, description FROM job_listings LIMIT 10")
        job_listings = [{"id": row[0], "title": row[1], "description": row[2]} for row in cursor.fetchall()]
    return job_listings

@app.route("/")
def home():
    job_listings = get_job_listings_from_db()
    return render_template("index.html", job_listings=job_listings)

app.secret_key = 'supersecret'  # required for using session

# Feed Less, But Cleaner Resume Input
def clean_resume_text(text):
    text = re.sub(r'\s+', ' ', text)  # Remove excessive whitespace
    text = re.sub(r'(Page \d+ of \d+)', '', text, flags=re.I)  # Remove page headers
    return text.strip()


# Upload Resume
@app.route("/upload_resume/<int:job_id>", methods=["POST"])
def upload_resume(job_id):
    if 'resume' not in request.files:
        return "No resume file uploaded.", 400

    file = request.files['resume']
    if file.filename == '':
        return "No selected file.", 400

    filename = file.filename
    file_ext = os.path.splitext(filename)[1].lower()

    try:
        if file_ext == '.txt':
            resume_content = file.read().decode('utf-8', errors='ignore')
        elif file_ext == '.pdf':
            resume_content = extract_text_from_pdf(file)
        elif file_ext in ['.doc', '.docx']:
            resume_content = extract_text_from_docx(file)
        else:
            return "Unsupported file format", 400
    except Exception as e:
        return f"Error reading file: {str(e)}", 500

    # Fetch JD content from DB
    with connect_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT description FROM job_listings WHERE id = ?", (job_id,))
        jd_row = cursor.fetchone()
        if not jd_row:
            return "Job not found.", 404
        jd_content = jd_row[0]

    # Summarize JD
    jd_response = ollama.chat(model="phi",
                              messages=[{"role": "system", "content": "Summarize this job description: " + jd_content}])
    jd_summary = jd_response.get("message", {}).get("content", "")

    # Match resume with job summary
    match_prompt = (
        "You are an AI Resume Evaluator. Based on the job description summary and the candidate's resume, "
        "return ONLY a JSON object with the following keys:\n"
        "- match_score (integer between 0 and 100)\n"
        "- skills (list of strings)\n"
        "- experience (string)\n"
        "- education (string)\n"
        "- summary (string)\n"
        "- objective (string)\n\n"
        "Example format:\n"
        "{\n"
        "  \"match_score\": 85,\n"
        "  \"skills\": [\"Python\", \"React\", \"SQL\"],\n"
        "  \"experience\": \"5 years at XYZ Corp as a backend engineer\",\n"
        "  \"education\": \"B.Tech in Computer Science\",\n"
        "  \"summary\": \"Highly skilled backend engineer...\",\n"
        "  \"objective\": \"Looking to contribute to scalable web platforms.\"\n"
        "}"
    )

    response = ollama.chat(model="phi", messages=[
        {"role": "system", "content": match_prompt},
        {"role": "user", "content": f"Resume: {resume_content}\n\nJob Summary: {jd_summary}\n\nReturn only the JSON."}
    ])

    response_text = response.get("message", {}).get("content", "")
    logging.info(f"\U0001F50D RAW AI RESPONSE:\n{response_text}")

    # Extract JSON content
    json_match = re.search(r"```json\s*([\s\S]*?)```", response_text)
    json_text = json_match.group(1).strip() if json_match else response_text.strip()

    try:
        result = json.loads(json_text)
    except json.JSONDecodeError:
        logging.error("❌ Failed to parse JSON! Returning error response.")
        result = {
            "match_score": "Error parsing AI response",
            "skills": "Error parsing AI response",
            "experience": "Error parsing AI response",
            "education": "Error parsing AI response",
            "summary": "Error parsing AI response",
            "objective": "Error parsing AI response",
        }

    session['match_result'] = result
    return redirect(url_for("match_result"))

@app.route("/match_result")
def match_result():
    result = session.get("match_result", {})
    return render_template("match_result.html", result=result)

@app.route("/store_job_listings", methods=["POST"])
def store_job_listings():
    data = request.json
    job_listings = data.get("job_listings", [])
    if not job_listings:
        return jsonify({"error": "Job listings are required"}), 400

    with connect_db() as conn:
        cursor = conn.cursor()
        for job in job_listings:
            cursor.execute("INSERT INTO job_listings (title, description) VALUES (?, ?)",
                           (job["title"], job["description"]))
        conn.commit()

    return jsonify({"message": "Job listings stored successfully"})

@app.route("/get_job_listings", methods=["GET"])
def get_job_listings():
    job_listings = get_job_listings_from_db()
    return jsonify({"job_listings": job_listings})

@app.route("/summarize_jd", methods=["POST"])
def summarize_jd():
    data = request.json
    jd_content = data.get("jd_content", "")
    if not jd_content:
        return jsonify({"error": "Job description content is required"}), 400

    response = ollama.chat(model="phi",
                           messages=[{"role": "system", "content": "Summarize this job description: " + jd_content}])
    summary = response.get("message", {}).get("content", "")
    return jsonify({"summary": summary})

@app.route("/match_candidates", methods=["POST"])
def match_candidates():
    data = request.json
    jd_summary = data.get("jd_summary", "")
    resume = data.get("resume", "")
    if not jd_summary or not resume:
        return jsonify({"error": "Job description summary and resume are required"}), 400

    response = ollama.chat(model="phi", messages=[
        {"role": "system", "content": f"Match this resume: {resume} with job summary: {jd_summary} and return a score."}])
    match_score = response.get("message", {}).get("content", "0")

    return jsonify({"match_score": match_score})

@app.route("/shortlist_candidates", methods=["POST"])
def shortlist_candidates():
    data = request.json
    candidates = data.get("candidates", [])
    threshold = data.get("threshold", 70)

    shortlisted = [c for c in candidates if c.get("match_score", 0) >= threshold]
    return jsonify({"shortlisted_candidates": shortlisted})

@app.route("/schedule_interview", methods=["POST"])
def schedule_interview():
    data = request.json
    candidate_email = data.get("candidate_email", "")
    if not candidate_email:
        return jsonify({"error": "Candidate email is required"}), 400

    return jsonify({"message": f"Interview invitation sent to {candidate_email}"})

def extract_text_from_pdf(file):
    file_bytes = file.read()
    doc = fitz.open(stream=file_bytes, filetype="pdf")
    text = "\n".join([page.get_text() for page in doc])
    return text

def extract_text_from_docx(file):
    doc = docx.Document(file)
    text = "\n".join([para.text for para in doc.paragraphs])
    return text

if __name__ == "__main__":
    app.run(debug=True)
